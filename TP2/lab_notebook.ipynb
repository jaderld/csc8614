{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bd8aba",
   "metadata": {},
   "source": [
    "# CSC 8614 - Language Models\n",
    "## CI2 - Fine-tuning a language model for text classification\n",
    "\n",
    "In this TP, you will work on fine-tuning a language model to move from text generation to text classification, specifically working on Spam Detection.\n",
    "\n",
    "The exercise (and code) has been adapted from the book _Build a Large Language Model (From Scratch)_, by Sebastian Raschka, and its [official github repository](https://github.com/rasbt/LLMs-from-scratch).\n",
    "\n",
    "This TP will be done in this notebook, and requires some additional files (available from the course website). You will have to fill the missing portions of code, and perform some additional experiments by testing different parameters.\n",
    "\n",
    "Working on this TP:\n",
    "- The easiest way is probably to work directly on the notebook, using jupyter notebook or visual studio code. An alternative is also to use Google colab.\n",
    "- You should be able to run everything on your machine, but you can connect to the GPUs if needed.\n",
    "\n",
    "Some files are required, and are available on the course website:\n",
    "- `requirements.txt`\n",
    "- `gpt_utils.py`\n",
    "\n",
    "\n",
    "## About the report\n",
    "You will have to return this notebook (completed), as well as a mini-report (`TP2/rapport.md`).\n",
    "\n",
    "The notebook and report shall be submitted via a GitHub repository, similarly to what you did for the first session (remember to use a different folder: `TP2`).\n",
    "For the notebook, it is sufficient to complete the code and submit the final version.\n",
    "\n",
    "For the mini-report, you have to answer the questions asked in this notebook, and discuss some of your findings as requested.\n",
    "As for the first session:\n",
    "- \"Vous devez y mettre : réponses courtes, résultats observés (copie de sorties), captures d’écran demandées, et une courte interprétation.\"\n",
    "- \"Ne collez pas des pages entières : soyez concis et sélectionnez les éléments pertinents.\"\n",
    "\n",
    "Reproducibility: \n",
    "- fix a random seed and write it in the report\n",
    "- indicate in the report the specific python version OS, and the library versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e55fc",
   "metadata": {},
   "source": [
    "**Question 1**: Dans `TP1/rapport.md`, ajoutez immédiatement un court en-tête (quelques lignes) contenant : (i) votre nom/prénom, (ii) la commande d’installation/activation d’environnement utilisée, (iii) les versions (Python + bibliothèques principales).\n",
    "\n",
    "Ajoutez ensuite au fil du TP des sections/titres à votre convenance, tant que l’on peut retrouver clairement vos réponses et vos preuves d’exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af34f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.9.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.9.1)\n",
      "Requirement already satisfied: tiktoken==0.12.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: pandas==2.3.3 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (2.3.3)\n",
      "Requirement already satisfied: matplotlib==3.10.8 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (3.10.8)\n",
      "Requirement already satisfied: tensorflow==2.20.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (2.20.0)\n",
      "Requirement already satisfied: jupyterlab==4.5.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (4.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 1)) (3.20.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 1)) (2025.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from torch==2.9.1->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tiktoken==0.12.0->-r requirements.txt (line 2)) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tiktoken==0.12.0->-r requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tqdm==4.67.1->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from pandas==2.3.3->-r requirements.txt (line 4)) (2025.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from matplotlib==3.10.8->-r requirements.txt (line 5)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from matplotlib==3.10.8->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from matplotlib==3.10.8->-r requirements.txt (line 5)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from matplotlib==3.10.8->-r requirements.txt (line 5)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from matplotlib==3.10.8->-r requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from matplotlib==3.10.8->-r requirements.txt (line 5)) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from matplotlib==3.10.8->-r requirements.txt (line 5)) (3.3.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (6.33.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (3.13.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorflow==2.20.0->-r requirements.txt (line 6)) (0.5.4)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.28.1)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (7.1.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (5.9.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (6.5.4)\n",
      "Requirement already satisfied: traitlets in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab==4.5.1->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (25.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (8.8.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.23.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (27.1.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.0.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.13.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (4.26.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.12.0->-r requirements.txt (line 2)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.12.0->-r requirements.txt (line 2)) (2.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (3.1.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (25.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (0.45.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.8.19)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (9.9.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (7.2.1)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jinja2->torch==2.9.1->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.30.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-core->jupyterlab==4.5.1->-r requirements.txt (line 7)) (4.5.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (25.10.0)\n",
      "Requirement already satisfied: rich in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (0.18.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (4.14.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.21.2)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from sympy>=1.13.3->torch==2.9.1->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.23)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (2.8.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab==4.5.1->-r requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jaaad\\csc8614\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow==2.20.0->-r requirements.txt (line 6)) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# [Instructor code: install requirements]\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b498f1c",
   "metadata": {},
   "source": [
    "## Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6cd969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2_weights\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\vocab.bpe\n",
      "Weights downloaded and loaded into memory.\n"
     ]
    }
   ],
   "source": [
    "# --- [INSTRUCTOR CODE: load the model weights into memory] ---\n",
    "import torch\n",
    "import tiktoken\n",
    "from gpt_utils import GPTModel, download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "# Download the model weights (124M param version) / This function (which we put in gpt_utils) handles the downloading\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2_weights\")\n",
    "print(\"Weights downloaded and loaded into memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80dab0",
   "metadata": {},
   "source": [
    "The `settings` obtained with `download_and_load_gpt2` are the GPT-2 weights made publicly available by OpenAI.\n",
    "\n",
    "**Question 2**: What type is the object `setting`, and what is its structure (e.g. if it is a list, its length; if a dictionary, its keys, etc.)?\n",
    "\n",
    "**Question 3**: What type is the object `params`, and what is its structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6572fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2_weights\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2_weights\\124M\\vocab.bpe\n",
      "Weights downloaded and loaded into memory.\n",
      "\n",
      "=== Question 2: Settings ===\n",
      "Type of settings: <class 'dict'>\n",
      "Keys of settings: dict_keys(['n_vocab', 'n_ctx', 'n_embd', 'n_head', 'n_layer'])\n",
      "n_layer: 12\n",
      "n_head: 12\n",
      "n_embd: 768\n",
      "vocab_size: None\n",
      "act_fn: None\n",
      "\n",
      "=== Question 3: Params ===\n",
      "Type of params: <class 'dict'>\n",
      "Number of parameters: 5\n",
      "Some parameter keys: ['blocks', 'b', 'g', 'wpe', 'wte']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# TP2 – GPT-2 Spam Detection Setup\n",
    "# Questions 2, 3, 4\n",
    "# -------------------------------\n",
    "\n",
    "# Step 0: Imports and reproducibility\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from gpt_utils import GPTModel, download_and_load_gpt2\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Step 1: Download GPT-2 124M weights\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2_weights\")\n",
    "print(\"Weights downloaded and loaded into memory.\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# Question 2: Analyse settings\n",
    "# -------------------------------\n",
    "print(\"=== Question 2: Settings ===\")\n",
    "print(\"Type of settings:\", type(settings))\n",
    "print(\"Keys of settings:\", settings.keys())\n",
    "\n",
    "# Example: print key hyperparameters\n",
    "print(\"n_layer:\", settings.get(\"n_layer\"))\n",
    "print(\"n_head:\", settings.get(\"n_head\"))\n",
    "print(\"n_embd:\", settings.get(\"n_embd\"))\n",
    "print(\"vocab_size:\", settings.get(\"vocab_size\"))\n",
    "print(\"act_fn:\", settings.get(\"act_fn\"))\n",
    "print()\n",
    "\n",
    "# -------------------------------\n",
    "# Question 3: Analyse params\n",
    "# -------------------------------\n",
    "print(\"=== Question 3: Params ===\")\n",
    "print(\"Type of params:\", type(params))\n",
    "print(\"Number of parameters:\", len(params))\n",
    "print(\"Some parameter keys:\", list(params.keys())[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aed6d2",
   "metadata": {},
   "source": [
    "Look at the `GPTModel` in the file `gpt_utils.py`. In the `__init__` method, we have to pass a config (parameter `cfg`). \n",
    "\n",
    "**Question 4:** \n",
    "Analyse the `__init__` method, and check what is the required structure for the `cfg` parameter. Is the `settings` variable we have obtained in the right format? If not, perform the mapping to convert the variable `setting` into a variable `model_config` with the right structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e344cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Question 4: Map settings to model_config\n",
    "# -------------------------------\n",
    "\n",
    "# Fixed values for GPT-2 124M\n",
    "vocab_size = 50257\n",
    "context_length = 1024\n",
    "emb_dim = settings[\"n_embd\"]\n",
    "n_layers = settings[\"n_layer\"]\n",
    "n_heads = settings[\"n_head\"]      # required by TransformerBlock\n",
    "drop_rate = 0.1\n",
    "qkv_bias = True\n",
    "\n",
    "model_config = {\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"emb_dim\": emb_dim,\n",
    "    \"context_length\": context_length,\n",
    "    \"drop_rate\": drop_rate,\n",
    "    \"n_layers\": n_layers,\n",
    "    \"n_heads\": n_heads,        # must include for TransformerBlock\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": True,     # must include for TransformerBlock\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db6837eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 Model Loaded and Configured successfully!\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(model_config)\n",
    "\n",
    "# Load the pre-trained weights\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval() \n",
    "\n",
    "print(\"GPT-2 Model Loaded and Configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb45e0b",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Context from the lecture: The raw data is just text messages. \n",
    "\n",
    "The model needs numbers (token IDs). We also need to pad the messages so they are all the same length in a batch.\n",
    "\n",
    "We will use a `SpamDataset` class (provided below) to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34fe9b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples loaded: 5572\n",
      "Created 'train.csv' and 'test.csv' successfully!\n",
      "Train size: 4457\n",
      "Test size: 1115\n"
     ]
    }
   ],
   "source": [
    "# --- [INSTRUCTOR CODE: Run this cell to define the Dataset Class] ---\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=120, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = pad_token_id\n",
    "        # Encode labels: \"spam\" -> 1, \"ham\" -> 0\n",
    "        self.data[\"label_encoded\"] = self.data[\"Label\"].map({\"spam\": 1, \"ham\": 0})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx][\"Text\"]\n",
    "        label = self.data.iloc[idx][\"label_encoded\"]\n",
    "        # Tokenize\n",
    "        encoded = self.tokenizer.encode(text, allowed_special={'<|endoftext|>'})       \n",
    "        # Truncate if too long\n",
    "        encoded = encoded[:self.max_length]\n",
    "        # Pad if too short\n",
    "        pad_len = self.max_length - len(encoded)\n",
    "        encoded += [self.pad_token_id] * pad_len\n",
    "        return torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Download the dataset zip file\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extract_path = \"sms_spam_collection\"\n",
    "data_file_path = os.path.join(extract_path, \"SMSSpamCollection\")\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    print(\"Download complete.\")\n",
    "# Unzip\n",
    "if not os.path.exists(extract_path):\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "# Read the TSV file\n",
    "df = pd.read_csv(\n",
    "    data_file_path, \n",
    "    sep=\"\\t\", \n",
    "    header=None, \n",
    "    names=[\"Label\", \"Text\"]\n",
    ")\n",
    "print(f\"Total samples loaded: {len(df)}\")\n",
    "\n",
    "# 4. Create Train/Test Split (80 train / 20 test)\n",
    "df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "# Split index\n",
    "split_idx = int(0.8 * len(df))\n",
    "\n",
    "# TODO: if needed (for performance resons), you can come back here and reduce the size of the training set.\n",
    "train_df = df.iloc[:split_idx]  # [:2000]  # Readd this to only consider 2000 training samples\n",
    "test_df = df.iloc[split_idx:]\n",
    "\n",
    "# Save as CSVs, so the SpamDataset class can read them.\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "print(\"Created 'train.csv' and 'test.csv' successfully!\")\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1836438",
   "metadata": {},
   "source": [
    "**Question 5.1**: In the cell above, why did we do `df = df.sample(frac=1, random_state=123)` when creating the train/test split?\n",
    "\n",
    "**Question 5.2**: Analyse the datasets, what is the distribution of the two classes in the train set? Are they balanced or unbalanced? In case they are unbalanced, might this lead to issues for the fine-tuning of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75032163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set:\n",
      "Label\n",
      "ham     3860\n",
      "spam     597\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class percentages:\n",
      "Label\n",
      "ham     86.60534\n",
      "spam    13.39466\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the train dataset\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Count class distribution\n",
    "class_counts = train_data[\"Label\"].value_counts()\n",
    "print(\"Class distribution in training set:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Compute percentages\n",
    "class_percent = 100 * class_counts / len(train_data)\n",
    "print(\"\\nClass percentages:\")\n",
    "print(class_percent)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_counts.plot(kind=\"bar\", color=[\"skyblue\", \"salmon\"])\n",
    "plt.title(\"Training Set Class Distribution\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942400a0",
   "metadata": {},
   "source": [
    "**Question 6**: Create the dataloaders for training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc53c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([16, 120])\n",
      "Target batch shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Tokenizer already created\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Dataset instances\n",
    "train_dataset = SpamDataset(\"train.csv\", tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", tokenizer)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "\n",
    "# 1. Train loader: shuffle=True\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 2. Test loader: shuffle=False\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb1bc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([16, 120])\n",
      "Target batch shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# Check your work\n",
    "for input_batch, target_batch in train_loader:\n",
    "    print(\"Input batch shape:\", input_batch.shape) # Should be [16, 120] (unless you use batch_size != 16)\n",
    "    print(\"Target batch shape:\", target_batch.shape) # Should be [16]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac363ae",
   "metadata": {},
   "source": [
    "**Question 7**: Looking at the batch size and the training size, how many batches will you have in total? Please report the size of the subsampled training data, you reduce it due to performance constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampled training size: 2000\n",
      "Number of batches per epoch: 125\n"
     ]
    }
   ],
   "source": [
    "subsample_size = 2000  # can reduce from full train set (~4179)\n",
    "train_dataset_small = torch.utils.data.Subset(train_dataset, range(subsample_size))\n",
    "\n",
    "batch_size = 16\n",
    "num_batches = (len(train_dataset_small) + batch_size - 1) // batch_size\n",
    "print(f\"Subsampled training size: {len(train_dataset_small)}\")\n",
    "print(f\"Number of batches per epoch: {num_batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92492b3f",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeab783",
   "metadata": {},
   "source": [
    "**Context**: GPT-2 was trained to predict the next word (output size ~50,000). We want to predict binary classes (output size 2), so we must replace the final layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964803ec",
   "metadata": {},
   "source": [
    "**Question 8**:\n",
    "\n",
    "**8.1**: In the cell below, define the number of output classes (`num_classes`) for the new spam detection task.\n",
    "\n",
    "**8.2**: Also, pring the original and updated output heads (hint: `out_head` from `GPTModel`)\n",
    "\n",
    "**8.3**: Why do we freeze the internal layers with `param.requires_grad = False`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d5a5910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original output head: Linear(in_features=768, out_features=50257, bias=False)\n",
      "New output head: Linear(in_features=768, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Freeze the internal layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Print the original output head\n",
    "print(f\"Original output head: {model.out_head}\")\n",
    "\n",
    "# Define number of output classes\n",
    "num_classes = 2  # spam / ham\n",
    "\n",
    "# Replace the output head\n",
    "# GPT-2 small hidden size is 768\n",
    "model.out_head = nn.Linear(768, num_classes)\n",
    "\n",
    "# Enable gradient calculation ONLY for the new head and the final LayerNorm\n",
    "for param in model.out_head.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.trf_blocks[-1].norm2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Print the new output head\n",
    "print(f\"New output head: {model.out_head}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef4e51",
   "metadata": {},
   "source": [
    "You now have to **finalise the code for the training loop** (see individual steps below).\n",
    "\n",
    "In the first cell below you can find the code to move the model to GPU (if available), define the optimizer, and calculate the accuracy. The following cell contains the code for the training (fine-tuning) loop.\n",
    "\n",
    "You will have to complete the code of the training loop, by answering the following questions:\n",
    "\n",
    "**Question 9.1**: Reset the gradients of the `optimizer` ([hint](https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html)).\n",
    "\n",
    "**Question 9.2**: Compute cross-entropy loss ([hint](https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html)).\n",
    "\n",
    "**Question 9.3**: Add code for the backward pass, to compute the gradient ([hint](https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html))\n",
    "\n",
    "**Question 9.4**: Add code for the optimizer step, to update the weights ([hint](https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html))\n",
    "\n",
    "**Question 9.5**: Add code to calculate the accuracy on train and test (hint: you can use the `calc_accuracy` method).\n",
    "\n",
    "**Note about the speed**: On my laptop's CPU 1 epoch with the full training dataset (~4400 samples, batch_size=16) took ~20 minutes; 1 epoch with a train set of 2000 samples (batch_size=16) took ~12 minutes. \n",
    "\n",
    "To iterate more quickly, you could:\n",
    "- i) set `num_epochs = 1` (but only at the beginning), just to make sure that the code is working;\n",
    "- ii) increase batch_size to 32 or 64 (but careful with possible memory issues).\n",
    "- iii) reduce the size of the training dataset, by going back to the *Preparing the data* section, and changing the line `train_df = df.iloc[:split_idx]` to `train_df = df.iloc[:split_idx][:2000]` or similar. Be careful that if you reduce the training data too much, the model will not have enough data for fine-tuning.\n",
    "- Use a GPU; it would be much quicker (few minutes on the whole training data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c48da4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class weights: tensor([1.0000, 6.4657])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Measure imbalance\n",
    "count_ham = len(train_df[train_df['Label']=='ham'])\n",
    "count_spam = len(train_df[train_df['Label']=='spam'])\n",
    "\n",
    "# Calculate class weights: penalize missing the minority class (Spam) more\n",
    "pos_weight = count_ham / count_spam\n",
    "class_weights = torch.tensor([1.0, pos_weight]).to(device)\n",
    "print(f\"Using class weights: {class_weights}\")\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.1)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "def calc_accuracy(loader, model, device):\n",
    "    correct, total = 0, 0\n",
    "    # Track spam specifically\n",
    "    spam_correct, spam_total = 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            logits = model(inputs)[:, -1, :]\n",
    "            predicted = torch.argmax(logits, dim=-1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Filter for Spam (Label 1)\n",
    "            spam_mask = (labels == 1)\n",
    "            spam_total += spam_mask.sum().item()\n",
    "            spam_correct += (predicted[spam_mask] == labels[spam_mask]).sum().item()\n",
    "    # Avoid division by zero\n",
    "    spam_acc = spam_correct / spam_total if spam_total > 0 else 0.0\n",
    "    global_acc = correct / total\n",
    "    return global_acc, spam_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e30f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 0.6500\n",
      "Epoch 1, Batch 10, Loss: 0.7557\n",
      "Epoch 1, Batch 20, Loss: 0.7856\n",
      "Epoch 1, Batch 30, Loss: 0.7110\n",
      "Epoch 1, Batch 40, Loss: 0.7362\n",
      "Epoch 1, Batch 50, Loss: 0.6807\n",
      "Epoch 1, Batch 60, Loss: 0.4179\n",
      "Epoch 1, Batch 70, Loss: 0.6205\n",
      "Epoch 1, Batch 80, Loss: 1.1277\n",
      "Epoch 1, Batch 90, Loss: 0.6747\n",
      "Epoch 1, Batch 100, Loss: 0.6561\n",
      "Epoch 1, Batch 110, Loss: 0.5817\n",
      "Epoch 1, Batch 120, Loss: 0.5092\n",
      "Epoch 1, Batch 130, Loss: 0.6022\n",
      "Epoch 1, Batch 140, Loss: 0.6624\n",
      "Epoch 1, Batch 150, Loss: 0.3908\n",
      "Epoch 1, Batch 160, Loss: 0.6139\n",
      "Epoch 1, Batch 170, Loss: 0.2548\n",
      "Epoch 1, Batch 180, Loss: 0.4623\n",
      "Epoch 1, Batch 190, Loss: 0.5067\n",
      "Epoch 1, Batch 200, Loss: 0.4477\n",
      "Epoch 1, Batch 210, Loss: 0.5390\n",
      "Epoch 1, Batch 220, Loss: 0.2957\n",
      "Epoch 1, Batch 230, Loss: 0.7264\n",
      "Epoch 1, Batch 240, Loss: 0.2122\n",
      "Epoch 1, Batch 250, Loss: 0.9020\n",
      "Epoch 1, Batch 260, Loss: 0.7302\n",
      "Epoch 1, Batch 270, Loss: 0.3962\n",
      "Epoch 1: Train Acc: 62.55% (Spam: 97.15%) | Test Acc: 64.66% (Spam: 98.00%)\n",
      "Epoch 2, Batch 0, Loss: 0.4119\n",
      "Epoch 2, Batch 10, Loss: 0.7901\n",
      "Epoch 2, Batch 20, Loss: 0.8120\n",
      "Epoch 2, Batch 30, Loss: 0.3606\n",
      "Epoch 2, Batch 40, Loss: 0.2911\n",
      "Epoch 2, Batch 50, Loss: 0.3636\n",
      "Epoch 2, Batch 60, Loss: 0.3509\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m optimizer.zero_grad()\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Forward Pass (last token only)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m[:, -\u001b[32m1\u001b[39m, :]  \u001b[38;5;66;03m# shape: [batch_size, num_classes]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 9.2. Calculate the cross entropy loss\u001b[39;00m\n\u001b[32m     15\u001b[39m loss = criterion(logits, targets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\TP2\\gpt_utils.py:227\u001b[39m, in \u001b[36mGPTModel.forward\u001b[39m\u001b[34m(self, in_idx)\u001b[39m\n\u001b[32m    225\u001b[39m x = tok_embeds + pos_embeds  \u001b[38;5;66;03m# Shape [batch_size, num_tokens, emb_size]\u001b[39;00m\n\u001b[32m    226\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_emb(x)\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrf_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_norm(x)\n\u001b[32m    229\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.out_head(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\TP2\\gpt_utils.py:193\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    191\u001b[39m shortcut = x\n\u001b[32m    192\u001b[39m x = \u001b[38;5;28mself\u001b[39m.norm2(x)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_resid(x)\n\u001b[32m    195\u001b[39m x = x + shortcut  \u001b[38;5;66;03m# Add the original input back\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\TP2\\gpt_utils.py:164\u001b[39m, in \u001b[36mFeedForward.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaaad\\csc8614\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # 9.1. Reset Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass (last token only)\n",
    "        logits = model(inputs)[:, -1, :]  # shape: [batch_size, num_classes]\n",
    "\n",
    "        # 9.2. Calculate the cross entropy loss\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        # 9.3. Backward Pass\n",
    "        loss.backward()\n",
    "\n",
    "        # 9.4 Optimizer Step\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # 9.5 Calculate the accuracy on train and test\n",
    "    train_acc, train_spam_acc = calc_accuracy(train_loader, model, device)\n",
    "    test_acc, test_spam_acc = calc_accuracy(test_loader, model, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Acc: {train_acc*100:.2f}% (Spam: {train_spam_acc*100:.2f}%) | \"\n",
    "          f\"Test Acc: {test_acc*100:.2f}% (Spam: {test_spam_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2cee15",
   "metadata": {},
   "source": [
    "**Question 10**: \n",
    "\n",
    "Now run the cell above. You should see how the training loss changes after each batch (and epoch).\n",
    "Describe thie trend: what do you see, is the model learning?\n",
    "\n",
    "**Question 11 (optional)**: Change the number of epochs and/or the learning rate and/or the size of the training data, and investigate how the loss/accuracy of the model changes. You can do this editing and re-running the cells above, or creating new cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed the code directly in the previous cell. Learning Rate went from 5e-5 to 1e-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3ef76",
   "metadata": {},
   "source": [
    "**Question 12 (optional)**: Now test the model *on your own text*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed98ef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: 'Hey, are we still meeting for lunch tomorrow at 12?' -> Prediction: NOT SPAM\n",
      "Text 2: 'URGENT! You have won a FREE iPhone. Click here to claim your prize now! Call 0800-123-456.' -> Prediction: NOT SPAM\n"
     ]
    }
   ],
   "source": [
    "def classify_text(text, model, tokenizer, device, max_length=120, pad_token_id=50256):\n",
    "    model.eval()\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded = encoded[:max_length]\n",
    "    pad_len = max_length - len(encoded)\n",
    "    encoded += [pad_token_id] * pad_len\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(encoded_tensor)[:, -1, :]\n",
    "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"SPAM\" if predicted_label == 1 else \"NOT SPAM\"\n",
    "\n",
    "# --- Tests ---\n",
    "# Texte 1 : Message conversationnel normal\n",
    "text_1 = \"Hey, are we still meeting for lunch tomorrow at 12?\" \n",
    "\n",
    "# Texte 2 : Message frauduleux typique (Urgence + Gratuité + Lien)\n",
    "text_2 = \"URGENT! You have won a FREE iPhone. Click here to claim your prize now! Call 0800-123-456.\"\n",
    "\n",
    "print(f\"Text 1: '{text_1}' -> Prediction: {classify_text(text_1, model, tokenizer, device)}\")\n",
    "print(f\"Text 2: '{text_2}' -> Prediction: {classify_text(text_2, model, tokenizer, device)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba90e8",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
